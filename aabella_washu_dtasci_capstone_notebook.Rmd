---
title: 'Coursera WashU Dtasci Capstone Project: BLIGHT'
always_allow_html: yes
output:
  html_notebook: default
---

Loading libraries
```{r, include=FALSE}
library(readr)
library(magrittr)
library(dplyr)
#install.packages("lucr")
library(lucr)
#install.packages("lubridate")
library(lubridate)
#install.packages("rbokeh")
library(rbokeh)
#install.packages("geosphere")
library(geosphere)
```

Setting data location, make sure the files below are available so the rest runs
```{r}
datadir <- "../data"
list.files(datadir)
```

Loading data permits -- mainly blight incidents
```{r}
data_permits <- read_tsv(paste(datadir, "detroit-demolition-permits.tsv", sep="/"))
head(data_permits)
```

Data permits exploration
```{r}
#converting to factors
cols <- c("CASE_TYPE", "CASE_DESCRIPTION", "LEGAL_USE", "BLD_PERMIT_TYPE",
          "PERMIT_DESCRIPTION", "BLD_PERMIT_DESC", "BLD_TYPE_USE", "RESIDENTIAL",
          "DESCRIPTION", "BLD_TYPE_CONST_COD", "BLD_ZONING_DIST", "BLD_USE_GROUP",
          "BLD_BASEMENT", "FEE_TYPE", "CSF_CREATED_BY","CONDITION_FOR_APPROVAL")
data_permits %<>% mutate_each_(funs(factor(.)),cols)

#converting $$ to numeric
cols <- c("PCF_AMT_PD", "PCF_AMT_DUE", "PCF_UPDATED","ESTIMATED_COST")
data_permits %<>% mutate_each_(funs(from_currency(.)),cols)

#converting to dates
cols <-c("PERMIT_APPLIED","PERMIT_ISSUED","PERMIT_EXPIRES")
# to use lubridate, need to figure it out -- 
data_permits %<>% mutate_each_(funs(parse_date_time(.,orders="mdy",tz="America/Detroit")),cols)
summary(data_permits)
```
Extracting building lat longs
```{r}
data_permits %<>%
  #filter out permits that have no lat/long
  filter(grepl("\\([0-9\\.\\-]+, *[0-9\\.\\-]+\\)",site_location)) %>%
  #extracting lat longs
  mutate(lat = as.double(sub(".*\\(([0-9\\.\\-]+),.*","\\1", site_location))) %>%
  mutate(long = as.double(sub(".*, *([0-9\\.\\-]+).*","\\1", site_location)))
```

Create a list of buildings
```{r}
bld_list <- data_permits %>%
  mutate(r = sqrt(PARCEL_SIZE/pi) ) %>%
  select(PARCEL_NO, LOT_NUMBER, PERMIT_ISSUED, PARCEL_SIZE, lat, long, r) %>%
  arrange(PARCEL_NO, desc(PERMIT_ISSUED)) %>%
  group_by(PARCEL_NO) %>%
  summarise(n_permits=n(), last_permit=first(PERMIT_ISSUED), 
            lat=last(lat), long=last(long), r=last(r))
bld_list
```

Plot lat/longs to a map
- centering to Detroit 42.3314 N, 83.0458 W
- more about rbokeh: http://hafen.github.io/rbokeh/rd.html#gmap
- lots of cool maps: https://snazzymaps.com 
- Available styles are: “subtle_grayscale”, “shades_of_grey”, “blue_water”, “pale_dawn”, “blue_essence”, “apple_mapsesque”, “midnight_commander”, “light_monochrome”, “paper”, “retro”, “flat_map”, “cool_grey”
```{r}
p <- gmap(lat = 42.37, lng = -83.10, zoom = 11, width = 600, height = 350,
          map_style = gmap_style("apple_mapsesque")) %>%
  ly_points(long, lat, data = bld_list, hover = c(PARCEL_NO, r), 
            col = 'purple', alpha = 0.1) %>%
  x_axis(visible = FALSE) %>%
  y_axis(visible = FALSE)
p
```

Testing GeoSphere package to calculate distance between 2 lat/long coordinates
```{r}
#this should be around 1160ft according to Google Maps
#https://www.google.com/maps/dir/42.3655979,-71.1040001/42.3683169,-71.1017685/@42.3668028,-71.10503,17z/data=!4m2!4m1!3e2
m_in_ft <- 0.3048
distGeo(c(-71.1040001,42.3655979), c(-71.1017685,42.3683169))/m_in_ft
```

Create a function to output the buildings that are within proximity of lat/lon coordinates
```{r}
lt <- bld_list$lat[3]
ln <- bld_list$long[3]
rangeft <- 1500
bld_list %>% 
#  mutate(dt = distGeo(c(ln,lt), c(long, lat))/m_in_ft) %>%
  filter(!is.na(r)) %>%
  rowwise() %>%
  mutate(dt = distGeo(c(ln,lt),c(long,lat))/m_in_ft) %>%
  filter(dt <= rangeft + r) %>%
  head(10)

#distGeo(c(ln,lt),c(bld_list$long,bld_list$lat))
```
Function to return all buildings around a particular lat long within a predefined range (by default 500m or 1640ft)
- input data, for simplicity, should have 4 fields
  - PARCEL_NO: assumed it's a unique identifier for building)
  - lat: building lat coordinate
  - long: building long coordinate
  - r: estimated building's area radious (when area is approximated to circle)
- the other input variables are:
  - lt: target lat coordinate
  - ln: target long coordinate
  - rangeft (optional, range in feet to look buildings around target lat/long)
  - m_in_ft (option)
```{r}
bld_in_range <- function(data, lt, ln, rangeft = 1640, m_in_ft = 0.3048) {
  data %>% 
    filter(!is.na(r)) %>%
    rowwise() %>%
    mutate(dist_ft = distGeo(c(ln,lt),c(long,lat))/m_in_ft) %>%
    filter(dist_ft <= rangeft + r) %>%
    select(PARCEL_NO, dist_ft) %>%
    arrange(dist_ft)
}

indata <- bld_list %>% select(PARCEL_NO, lat, long, r)

lt <- bld_list$lat[3]
ln <- bld_list$long[3]

bld_in_range(indata, lt, ln)
```
Loading blight violation incidents
```{r}
data_violations <- read_csv(paste(datadir, "detroit-blight-violations.csv", sep="/"))
head(data_violations)
```

Data Violation exploration
```{r}
#converting to factors
cols <- c("AgencyName","ViolationCode","Disposition","PaymentStatus","Void",
          "ViolationCategory","Country")
data_violations %<>% mutate_each_(funs(factor(.)),cols)

#converting $$ to numeric
cols <- c("FineAmt","AdminFee","LateFee","StateFee","CleanUpCost","JudgmentAmt")
data_violations %<>% mutate_each_(funs(from_currency(.)),cols)

#converting to dates
cols <-c("TicketIssuedDT","HearingDT")
# to use lubridate, need to figure it out -- 
#data_violations %<>% mutate_each_(funs(from_currency(.)),cols)
summary(data_violations)
#dplyr::glimpse(data_violations)
```

Getting the violation codes
Need to categorize them
```{r}
violCodes <- data_violations %>% 
  select(ViolationCode, ViolDescription) %>%
  unique()
```

Generated lat/longs and address, and cleaned data
 1) Detroit addresses only, 
 2) removed Disposition "not responsible" and "PENDING JUDGEMENT" as might not be a violation
 Didn't filter by country as it removed most of the entries (from 300k to 13k!!)
```{r}
viol_list <- data_violations %>% 
#  filter(Country == "US") %>%
  filter(grepl("\\([0-9\\.\\-]+, *[0-9\\.\\-]+\\)",ViolationAddress)) %>%
  #extracting lat longs
  mutate(lat = as.double(sub(".*\\(([0-9\\.\\-]+),.*","\\1", ViolationAddress))) %>%
  mutate(long = as.double(sub(".*, *([0-9\\.\\-]+).*","\\1", ViolationAddress))) %>%
  mutate(address_only = sub("([^\\(]+)\\([0-9\\.\\-]+,.*","\\1", ViolationAddress)) %>%
  filter(grepl("Detroit",ViolationAddress)) %>%
  filter(! grepl("Not responsible",Disposition)) %>%
  filter(! grepl("PENDING", Disposition)) %>%
  select(lat, long, ViolationCode, Disposition, JudgmentAmt, PaymentStatus, ViolationCategory, address_only) 

head(viol_list)
```

What happens with Disposition?
```{r}
viol_list %>%
  select(Disposition) %>%
  group_by(Disposition) %>%
  summarise(n())
```

There are about 80k unique lat/longs, some of them generate a huge amount of violations, here are the top 30 lat/longs
```{r}
top30viols <- viol_list %>%
  select(lat, long) %>%
  mutate(geocord = paste(lat,long)) %>%
  group_by(geocord) %>%
  summarize(lat=last(lat), long=last(long), num_viols_in_geo = n()) %>%
  arrange(desc(num_viols_in_geo)) %>%
  head(30)
top30viols
```

Plotting them, we see that the top one has 13k violations and it's in the center of Detroit, probably a standard lat/long coordinate when not the actual is not available. I'm not sure about the others with over 1000 violations... 
```{r}
p <- gmap(lat = 42.37, lng = -83.10, zoom = 11, width = 600, height = 350,
          map_style = gmap_style("apple_mapsesque")) %>%
  ly_points(long, lat, data = top30viols, hover = num_viols_in_geo, 
            col = 'red', alpha = pmin(num_viols_in_geo / 1000, 1)) %>%
  x_axis(visible = FALSE) %>%
  y_axis(visible = FALSE)
p
```

```
Are there the same number of unique addresses?
```{r}
viol_list %>%
  select(address_only) %>%
  group_by(address_only) %>%
  summarize(num_viols_in_address = n()) %>%
  arrange(desc(num_viols_in_address))
```

Well, it seems that there are about 85k unique addresses, and 73k unique lat/longs.. 

Loading calls to 311, typically complains
```{r}
data_311 <- read_csv(paste(datadir, "detroit-311.csv", sep="/"))
head(data_311)
```

Loading criminal incidents in Detroit
```{r}
data_crime <- read_csv(paste(datadir, "detroit-crime.csv", sep="/"))
head(data_crime)
```

Next steps: 
Violations explorations
- How many were voided? Should we remove them?
- Map of violations.. potential facets by types
- Types of payment status
- Country? Non-US? 

311 calls exploration